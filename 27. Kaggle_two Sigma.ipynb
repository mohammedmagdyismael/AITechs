{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import dask as dk\n",
    "import pandas as pd\n",
    "import ast \n",
    "import pickle\n",
    "#import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import gc\n",
    "gc.enable()\n",
    "sns.set()\n",
    "sns.set_context(None)\n",
    "plt.rcParams['figure.figsize'] = [25, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will reduce data load for code test\n",
    "toy = False\n",
    "(market_train_df_cleaned, news_train_df_cleaned) = pd.read_pickle('./market_news_v2.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4072956, 16), (9328750, 24))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_train_df_cleaned.shape, news_train_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will reduce the number of samples for memory reasons\n",
    "if toy:\n",
    "    market_train_df_cleaned = market_train_df_cleaned.tail(100000)\n",
    "    news_train_df_cleaned = news_train_df_cleaned.tail(300000)\n",
    "else:\n",
    "    market_train_df_cleaned = market_train_df_cleaned.tail(3000000)\n",
    "    news_train_df_cleaned = news_train_df_cleaned.tail(6000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_cols_agg = {\n",
    "    'urgency': ['min', 'count'],\n",
    "    'relevance': ['min', 'max', 'mean', 'std'],\n",
    "    'sentimentNegative': ['min', 'max', 'mean', 'std'],\n",
    "    'sentimentNeutral': ['min', 'max', 'mean', 'std'],\n",
    "    'sentimentPositive': ['min', 'max', 'mean', 'std'],\n",
    "    'noveltyCount12H': ['min', 'max', 'mean', 'std'],\n",
    "    'noveltyCount24H': ['min', 'max', 'mean', 'std'],\n",
    "    'noveltyCount3D': ['min', 'max', 'mean', 'std'],\n",
    "    'noveltyCount5D': ['min', 'max', 'mean', 'std'],\n",
    "    'noveltyCount7D': ['min', 'max', 'mean', 'std'],\n",
    "    'volumeCounts12H': ['min', 'max', 'mean', 'std'],\n",
    "    'volumeCounts24H': ['min', 'max', 'mean', 'std'],\n",
    "    'volumeCounts3D': ['min', 'max', 'mean', 'std'],\n",
    "    'volumeCounts5D': ['min', 'max', 'mean', 'std'],\n",
    "    'volumeCounts7D': ['min', 'max', 'mean', 'std']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def join_market_news(market_train_df, news_train_df):\n",
    "    # Fix asset codes (str -> list)\n",
    "    news_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(\"'([\\w\\./]+)'\")    \n",
    "    # Expand assetCodes\n",
    "    assetCodes_expanded = list(chain(*news_train_df['assetCodes']))\n",
    "    assetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes'].apply(len) )\n",
    "    assert len(assetCodes_index) == len(assetCodes_expanded)\n",
    "    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n",
    "    # Create expandaded news (will repeat every assetCodes' row)\n",
    "    news_cols = ['time', 'assetCodes'] + sorted(news_cols_agg.keys())\n",
    "    news_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0', right_index=True, suffixes=(['','_old']))\n",
    "    # Free memory\n",
    "    del news_train_df, df_assetCodes\n",
    "    # Aggregate numerical news features\n",
    "    news_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg)\n",
    "    # Free memory\n",
    "    del news_train_df_expanded\n",
    "    # Convert to float32 to save memory\n",
    "    news_train_df_aggregated = news_train_df_aggregated.apply(np.float32)\n",
    "    # Flat columns\n",
    "    news_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n",
    "    # Join with train\n",
    "    market_train_df = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode'])\n",
    "    # Free memory\n",
    "    del news_train_df_aggregated\n",
    "    return market_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(market_train_df, news_train_df, le=None):\n",
    "    x, le = get_x(market_train_df, news_train_df)\n",
    "    y = market_train_df['returnsOpenNextMktres10'].clip(-1, 1)\n",
    "    return x, y, le\n",
    "\n",
    "\n",
    "def label_encode(series, min_count):\n",
    "    vc = series.value_counts()\n",
    "    le = {c:i for i, c in enumerate(vc.index[vc >= min_count])}\n",
    "    return le\n",
    "\n",
    "\n",
    "def get_x(market_train_df, news_train_df, le=None):\n",
    "    # Split date into before and after 22h (the time used in train data)\n",
    "    # E.g: 2007-03-07 23:26:39+00:00 -> 2007-03-08 00:00:00+00:00 (next day)\n",
    "    #      2009-02-25 21:00:50+00:00 -> 2009-02-25 00:00:00+00:00 (current day)\n",
    "    news_train_df['time'] = (news_train_df['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n",
    "\n",
    "    # Round time of market_train_df to 0h of curret day\n",
    "    market_train_df['time'] = market_train_df['time'].dt.floor('1D')\n",
    "\n",
    "    # Join market and news\n",
    "    x = join_market_news(market_train_df, news_train_df)\n",
    "    \n",
    "    # If not label-encoder... encode assetCode\n",
    "    if le is None:\n",
    "        le_assetCode = label_encode(x['assetCode'], min_count=10)\n",
    "        le_assetName = label_encode(x['assetName'], min_count=5)\n",
    "    else:\n",
    "        # 'unpack' label encoders\n",
    "        le_assetCode, le_assetName = le\n",
    "        \n",
    "    x['assetCode'] = x['assetCode'].map(le_assetCode).fillna(-1).astype(int)\n",
    "    x['assetName'] = x['assetName'].map(le_assetName).fillna(-1).astype(int)\n",
    "    \n",
    "    try:\n",
    "        x.drop(columns=['returnsOpenNextMktres10'], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        x.drop(columns=['universe'], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    x['dayofweek'], x['month'] = x.time.dt.dayofweek, x.time.dt.month\n",
    "    x.drop(columns='time', inplace=True)\n",
    "#    x.fillna(-1000,inplace=True)\n",
    "    \n",
    "    return x, (le_assetCode, le_assetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 16.3 s, total: 45.6 s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This will take some time...\n",
    "X, y, le = get_xy(market_train_df_cleaned, news_train_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000000, 73), (3000000,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save universe data for latter use\n",
    "universe = market_train_df_cleaned['universe']\n",
    "time = market_train_df_cleaned['time']\n",
    "\n",
    "# Free memory\n",
    "del market_train_df_cleaned, news_train_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 73)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(X.shape[0] * 0.8)\n",
    "X_train, y_train = X.iloc[:n_train], y.iloc[:n_train]\n",
    "X_valid, y_valid = X.iloc[n_train:], y.iloc[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For valid data, keep only those with universe > 0. This will help calculate the metric\n",
    "u_valid = (universe.iloc[n_train:] > 0)\n",
    "t_valid = time.iloc[n_train:]\n",
    "\n",
    "X_valid = X_valid[u_valid]\n",
    "y_valid = y_valid[u_valid]\n",
    "t_valid = t_valid[u_valid]\n",
    "del u_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat lgb datasets\n",
    "train_cols = X.columns.tolist()\n",
    "categorical_cols = [] # ['assetCode', 'assetName', 'dayofweek', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: y data is expected to be a pandas Series, as we will use its group_by function in `sigma_score`\n",
    "dtrain = lgb.Dataset(X_train.values, y_train, feature_name=train_cols, categorical_feature=categorical_cols, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(X_valid.values, y_valid, feature_name=train_cols, categorical_feature=categorical_cols, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will 'inject' an extra parameter in order to have access to df_valid['time'] inside sigma_score without globals\n",
    "dvalid.params = {\n",
    "    'extra_time': t_valid.factorize()[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = dict(\n",
    "    objective = 'regression_l1',\n",
    "    learning_rate = 0.1,\n",
    "    num_leaves = 127,\n",
    "    max_depth = -1,\n",
    "#     min_data_in_leaf = 1000,\n",
    "#     min_sum_hessian_in_leaf = 10,\n",
    "    bagging_fraction = 0.75,\n",
    "    bagging_freq = 2,\n",
    "    feature_fraction = 0.5,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 1.0,\n",
    "    metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n",
    "    seed = 42 # Change for better luck! :)\n",
    ")\n",
    "\n",
    "def sigma_score(preds, valid_data):\n",
    "    df_time = valid_data.params['extra_time']\n",
    "    labels = valid_data.get_label()\n",
    "    \n",
    "#    assert len(labels) == len(df_time)\n",
    "\n",
    "    x_t = preds * labels #  * df_valid['universe'] -> Here we take out the 'universe' term because we already keep only those equals to 1.\n",
    "    \n",
    "    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n",
    "    # is a pd.Series and call `group_by`\n",
    "    x_t_sum = x_t.groupby(df_time).sum()\n",
    "    score = x_t_sum.mean() / x_t_sum.std()\n",
    "\n",
    "    return 'sigma_score', score, True\n",
    "\n",
    "evals_result = {}\n",
    "m = lgb.train(lgb_params, dtrain, num_boost_round=1000, valid_sets=(dvalid,), valid_names=('valid',), verbose_eval=25,\n",
    "              early_stopping_rounds=100, feval=sigma_score, evals_result=evals_result)\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(evals_result['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_result.plot(figsize=(12, 8))\n",
    "ax.scatter(df_result['sigma_score'].idxmax(), df_result['sigma_score'].max(), marker='+', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round, valid_score = df_result['sigma_score'].idxmax()+1, df_result['sigma_score'].max()\n",
    "print(lgb_params)\n",
    "print(f'Best score was {valid_score:.5f} on round {num_boost_round}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 14))\n",
    "lgb.plot_importance(m, ax=ax[0])\n",
    "lgb.plot_importance(m, ax=ax[1], importance_type='gain')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train full model\n",
    "dtrain_full = lgb.Dataset(X, y, feature_name=train_cols, categorical_feature=categorical_cols)\n",
    "model = lgb.train(lgb_params, dtrain, num_boost_round=num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(predictions_template_df, market_obs_df, news_obs_df, le):\n",
    "    x, _ = get_x(market_obs_df, news_obs_df, le)\n",
    "    predictions_template_df.confidenceValue = np.clip(model.predict(x), -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = env.get_prediction_days()\n",
    "\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    make_predictions(predictions_template_df, market_obs_df, news_obs_df, le)\n",
    "    env.predict(predictions_template_df)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stock_by_news_assetName(assetName,stocks=market_train_df_cleaned):\n",
    "    # select all news releated to wal-mart\n",
    "    News  = news_train_df_cleaned['assetName'].str.contains(assetName)\n",
    "    # to get unique value from catigory\n",
    "    CodesAsString = news_train_df_cleaned[News]['assetCodes'].unique()\n",
    "    # convert value to object \n",
    "    Codes = ast.literal_eval(CodesAsString[0])\n",
    "#     print(Codes)\n",
    "    # get all assets has the same news assetcodes or any part \n",
    "    MarketStock = stocks[\"assetCode\"].isin(Codes)\n",
    "    del News, CodesAsString, Codes\n",
    "    return stocks[MarketStock]\n",
    " \n",
    "def get_all_stock_by_news_time(News, period ):\n",
    "    \"\"\"\n",
    "    news : news item \n",
    "    period : the time range to get data in future and in the past \n",
    "    \"\"\"\n",
    "    NewsTime  = News['time']\n",
    "    if(period < 0):\n",
    "        # past\n",
    "        time_limit   = pd.date_range(end  =NewsTime , periods=10, normalize = True )[0]\n",
    "        stocks_by_period = market_train_df_cleaned[(market_train_df_cleaned['time'] > time_limit) &(market_train_df_cleaned['time'] <= NewsTime)]\n",
    "    else:\n",
    "        # future \n",
    "        time_limit = pd.date_range(start=NewsTime , periods=10, normalize = True )[-1]       \n",
    "        stocks_by_period = market_train_df_cleaned[(market_train_df_cleaned['time'] > NewsTime) &( market_train_df_cleaned['time'] <= time_limit)]\n",
    "\n",
    "    # select all news releated to News assetName\n",
    "    stocks = get_all_stock_by_news_assetName(News['assetName'], stocks_by_period)\n",
    "    del NewsTime, time_limit, stocks_by_period\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>headlineTag</th>\n",
       "      <th>assetCodes</th>\n",
       "      <th>assetName</th>\n",
       "      <th>relevance</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ENR', 'ASIA', 'CN', 'NGS', 'EMRG', 'RTRS', '...</td>\n",
       "      <td>{'Z', 'O', 'OIL'}</td>\n",
       "      <td></td>\n",
       "      <td>{'0857.HK', '0857.F', '0857.DE', 'PTR.N'}</td>\n",
       "      <td>PetroChina Co Ltd</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 07:03:35+00:00</td>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'FEA', 'CA', 'LATAM', 'MX', 'INS', 'ASIA', 'I...</td>\n",
       "      <td>{'PGE', 'PCO', 'G', 'ESN', 'MD', 'PCU', 'DNP',...</td>\n",
       "      <td>FEATURE</td>\n",
       "      <td>{'STA.N'}</td>\n",
       "      <td>Travelers Companies Inc</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RET', 'ENR', 'ID', 'BG', 'US', 'PRESS', 'IQ'...</td>\n",
       "      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>{'WMT.DE', 'WMT.N'}</td>\n",
       "      <td>Wal-Mart Stores Inc</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...</td>\n",
       "      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>{'GOOG.O', 'GOOG.OQ', 'GOOGa.DE'}</td>\n",
       "      <td>Google Inc</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...</td>\n",
       "      <td>{'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...</td>\n",
       "      <td>PRESS DIGEST</td>\n",
       "      <td>{'XMSR.O'}</td>\n",
       "      <td>XM Satellite Radio Holdings Inc</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  \\\n",
       "0 2007-01-01 04:29:32+00:00   \n",
       "1 2007-01-01 07:03:35+00:00   \n",
       "2 2007-01-01 11:29:56+00:00   \n",
       "3 2007-01-01 12:08:37+00:00   \n",
       "4 2007-01-01 12:08:37+00:00   \n",
       "\n",
       "                                            headline  urgency  takeSequence  \\\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...        3             1   \n",
       "1          FEATURE-In kidnapping, finesse works best        3             1   \n",
       "2         PRESS DIGEST - Wall Street Journal - Jan 1        3             1   \n",
       "3              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "4              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "\n",
       "                                            subjects  \\\n",
       "0  {'ENR', 'ASIA', 'CN', 'NGS', 'EMRG', 'RTRS', '...   \n",
       "1  {'FEA', 'CA', 'LATAM', 'MX', 'INS', 'ASIA', 'I...   \n",
       "2  {'RET', 'ENR', 'ID', 'BG', 'US', 'PRESS', 'IQ'...   \n",
       "3  {'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...   \n",
       "4  {'FUND', 'FIN', 'CA', 'SFWR', 'INS', 'PUB', 'B...   \n",
       "\n",
       "                                           audiences   headlineTag  \\\n",
       "0                                  {'Z', 'O', 'OIL'}                 \n",
       "1  {'PGE', 'PCO', 'G', 'ESN', 'MD', 'PCU', 'DNP',...       FEATURE   \n",
       "2  {'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...  PRESS DIGEST   \n",
       "3  {'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...  PRESS DIGEST   \n",
       "4  {'T', 'DNP', 'PSC', 'U', 'D', 'M', 'RNP', 'PTD...  PRESS DIGEST   \n",
       "\n",
       "                                  assetCodes                        assetName  \\\n",
       "0  {'0857.HK', '0857.F', '0857.DE', 'PTR.N'}                PetroChina Co Ltd   \n",
       "1                                  {'STA.N'}          Travelers Companies Inc   \n",
       "2                        {'WMT.DE', 'WMT.N'}              Wal-Mart Stores Inc   \n",
       "3          {'GOOG.O', 'GOOG.OQ', 'GOOGa.DE'}                       Google Inc   \n",
       "4                                 {'XMSR.O'}  XM Satellite Radio Holdings Inc   \n",
       "\n",
       "   relevance       ...        noveltyCount12H  noveltyCount24H  \\\n",
       "0   0.235702       ...                      0                0   \n",
       "1   0.447214       ...                      1                1   \n",
       "2   0.377964       ...                      0                0   \n",
       "3   0.149071       ...                      0                0   \n",
       "4   0.149071       ...                      0                0   \n",
       "\n",
       "   noveltyCount3D  noveltyCount5D  noveltyCount7D  volumeCounts12H  \\\n",
       "0               0               0               0                0   \n",
       "1               1               1               1                1   \n",
       "2               0               0               0                0   \n",
       "3               0               0               0                0   \n",
       "4               0               0               0                0   \n",
       "\n",
       "   volumeCounts24H  volumeCounts3D  volumeCounts5D  volumeCounts7D  \n",
       "0                0               3               6               7  \n",
       "1                1               3               3               3  \n",
       "2                0               5              11              17  \n",
       "3                0               5              13              15  \n",
       "4                0               0               0               0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_train_df_cleaned.head(5)\n",
    "news_train_df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Market (Done)\n",
    "\n",
    "#LabelEncode AssetName \n",
    "labelencoder_market_assetname = LabelEncoder()\n",
    "market_train_df_cleaned.iloc[:, 2] = labelencoder_market_assetname.fit_transform(market_train_df_cleaned.iloc[:, 2])\n",
    "\n",
    "#LabelEncode AssetCode \n",
    "labelencoder_market_assetcode = LabelEncoder()\n",
    "market_train_df_cleaned.iloc[:, 1] = labelencoder_market_assetcode.fit_transform(market_train_df_cleaned.iloc[:, 1])\n",
    "\n",
    "\n",
    "#Eliminate Unused Attributes \n",
    "# we have to remove 'open','close', 'universe'\n",
    "market_train_df_usedCols = market_train_df_cleaned[['time',\t'assetCode',\t'assetName',\t'volume','open','close',\n",
    "                          'returnsClosePrevRaw1',\t'returnsOpenPrevRaw1',\n",
    "                          'returnsClosePrevRaw10',\t'returnsClosePrevMktres10',\n",
    "                          'returnsOpenPrevMktres10',\t'returnsOpenNextMktres10',\t'universe']]\n",
    "\n",
    "#market_train_df_usedCols.drops\n",
    "\n",
    "# free memmory \n",
    "#del market_train_df_cleaned\n",
    "\n",
    "#change time format\n",
    "market_train_df_usedCols['time'] = pd.to_datetime(market_train_df_usedCols.time)\n",
    "market_train_df_usedCols['time'] = market_train_df_usedCols['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#to decode the target label\n",
    "#ex: list(labelencoder_news_assetname.inverse_transform([6330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#News (Done)\n",
    "\n",
    "#LabelEncode AssetName \n",
    "labelencoder_news_assetname = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 8] = labelencoder_news_assetname.fit_transform(news_train_df_cleaned.iloc[:, 8])\n",
    "\n",
    "#LabelEncode AssetCode \n",
    "labelencoder_news_assetcode = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 7] = labelencoder_news_assetcode.fit_transform(news_train_df_cleaned.iloc[:, 7])\n",
    "\n",
    "#LabelEncode Subjects \n",
    "labelencoder_news_subjects = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 4] = labelencoder_news_subjects.fit_transform(news_train_df_cleaned.iloc[:, 4])\n",
    "\n",
    "#LabelEncode Audiences \n",
    "labelencoder_news_audiences = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 5] = labelencoder_news_audiences.fit_transform(news_train_df_cleaned.iloc[:, 5])\n",
    "\n",
    "#Eliminate Unused Attributes \n",
    "news_train_df_usedCols = news_train_df_cleaned[['time',\t'urgency',\t'subjects'\n",
    "                      ,\t'audiences',\t\t'assetCodes',\t'assetName'\n",
    "                      ,\t'relevance',\t'sentimentClass',\t'sentimentNegative',\t\n",
    "                      'sentimentNeutral',\t'sentimentPositive','noveltyCount12H','noveltyCount24H',\n",
    "                      'noveltyCount3D',\t'noveltyCount5D',\t'noveltyCount7D',\t'volumeCounts12H',\n",
    "                      'volumeCounts24H',\t'volumeCounts3D',\t'volumeCounts5D',\t'volumeCounts7D','volumeCounts7D']]\n",
    "\n",
    "# free Memmory \n",
    "#del news_train_df_cleaned\n",
    "\n",
    "#change time format\n",
    "news_train_df_usedCols['time'] =pd.to_datetime(news_train_df_usedCols.time)\n",
    "news_train_df_usedCols['time'] = news_train_df_usedCols['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "#Get Number of Unique items in attribute\n",
    "#ex: news_train_df_usedCols['subjects'].unique()\n",
    "\n",
    "#to decode the target label\n",
    "#ex: list(labelencoder_news_assetname.inverse_transform([6330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_train_df_usedCols.to_csv(\"market.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df_usedCols.to_csv(\"news.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dask' has no attribute 'dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-07c56782eae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_dataframes_bydate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_train_df_usedCols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_train_df_usedCols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dask' has no attribute 'dataframe'"
     ]
    }
   ],
   "source": [
    "merged_dataframes_bydate = dk.dataframe.merge(news_train_df_usedCols, market_train_df_usedCols, left_on='time', right_on='time' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_datetime64tz_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-420aeb5f905d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/dask/dataframe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from .core import (DataFrame, Series, Index, _Frame, map_partitions,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    repartition)\n\u001b[1;32m      5\u001b[0m from .io import (from_array, from_bcolz, from_array, from_bcolz,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m from .indexing import (_partition_of_index_value, _loc, _try_loc,\n\u001b[1;32m     31\u001b[0m                        _coerce_loc_index, _maybe_partial_time_string)\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeta_nonempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_meta_param_description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mno_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'__no_default__'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtoolz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_datetime64tz_dtype'"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: n , Output: 1\n",
    "n_input = #no. of attributes\n",
    "lr = 0.001\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "#Step 01: Spliting data (trainset, testset)\n",
    "#x: all IV attributes after merging \n",
    "#y: DV (returnsOpenNextMktres10)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Step 02:Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Step 03: Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, input_dim=n_input, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#Step 04: Compile and Save\n",
    "model.compile(loss='mse', optimizer=Adam (lr=lr))\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "#Step 05: Prediction \n",
    "ynew = model.predict(Xnew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Number of rows:\", market_train_df_usedCols.shape[0] )\n",
    "market_train_df_usedCols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train_df_cleaned = pd.read_csv(\"./datasets/news_sample.csv\")\n",
    "market_train_df_cleaned = pd.read_csv(\"./datasets/marketdata_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_train_df_cleaned['time'] =pd.to_datetime(news_train_df_cleaned.time)\n",
    "news_train_df_cleaned['time'] = news_train_df_cleaned['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "market_train_df_cleaned['time'] =pd.to_datetime(market_train_df_cleaned.time)\n",
    "market_train_df_cleaned['time'] = market_train_df_cleaned['time'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>universe</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <th>returnsClosePrevMktres1</th>\n",
       "      <th>returnsOpenPrevMktres1</th>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <th>returnsOpenPrevRaw10</th>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>A.N</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2606900.0</td>\n",
       "      <td>32.19</td>\n",
       "      <td>32.17</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>AAI.N</td>\n",
       "      <td>AirTran Holdings Inc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2051600.0</td>\n",
       "      <td>11.12</td>\n",
       "      <td>11.08</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078708</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>AAP.N</td>\n",
       "      <td>Advance Auto Parts Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1164800.0</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.99</td>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23747329.0</td>\n",
       "      <td>84.74</td>\n",
       "      <td>86.23</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>-0.037182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>ABB.N</td>\n",
       "      <td>ABB Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1208600.0</td>\n",
       "      <td>18.02</td>\n",
       "      <td>18.01</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time assetCode                 assetName  universe      volume  \\\n",
       "0  2007-02-01       A.N  Agilent Technologies Inc       1.0   2606900.0   \n",
       "1  2007-02-01     AAI.N      AirTran Holdings Inc       0.0   2051600.0   \n",
       "2  2007-02-01     AAP.N    Advance Auto Parts Inc       1.0   1164800.0   \n",
       "3  2007-02-01    AAPL.O                 Apple Inc       1.0  23747329.0   \n",
       "4  2007-02-01     ABB.N                   ABB Ltd       1.0   1208600.0   \n",
       "\n",
       "   close   open  returnsClosePrevRaw1  returnsOpenPrevRaw1  \\\n",
       "0  32.19  32.17              0.005938             0.005312   \n",
       "1  11.12  11.08              0.004517            -0.007168   \n",
       "2  37.51  37.99             -0.011594             0.025648   \n",
       "3  84.74  86.23             -0.011548             0.016324   \n",
       "4  18.02  18.01              0.011791             0.025043   \n",
       "\n",
       "   returnsClosePrevMktres1  returnsOpenPrevMktres1  returnsClosePrevRaw10  \\\n",
       "0                      NaN                     NaN              -0.001860   \n",
       "1                      NaN                     NaN              -0.078708   \n",
       "2                      NaN                     NaN               0.014332   \n",
       "3                      NaN                     NaN              -0.048613   \n",
       "4                      NaN                     NaN               0.012929   \n",
       "\n",
       "   returnsOpenPrevRaw10  returnsClosePrevMktres10  returnsOpenPrevMktres10  \\\n",
       "0              0.000622                       NaN                      NaN   \n",
       "1             -0.088066                       NaN                      NaN   \n",
       "2              0.045405                       NaN                      NaN   \n",
       "3             -0.037182                       NaN                      NaN   \n",
       "4              0.020397                       NaN                      NaN   \n",
       "\n",
       "   returnsOpenNextMktres10  \n",
       "0                 0.034672  \n",
       "1                 0.027803  \n",
       "2                 0.024433  \n",
       "3                -0.007425  \n",
       "4                -0.017994  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Market\n",
    "market_train_df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sourceTimestamp</th>\n",
       "      <th>firstCreated</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>e58c6279551b85cf</td>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...</td>\n",
       "      <td>{'O', 'Z', 'OIL'}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>5a31c4327427f63f</td>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...</td>\n",
       "      <td>{'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>1cefd27a40fabdfe</td>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'IQ', 'RO', 'US', 'ID', 'RET', 'RTRS', 'ENR',...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time            sourceTimestamp               firstCreated  \\\n",
       "0  2007-01-01  2007-01-01 04:29:32+00:00  2007-01-01 04:29:32+00:00   \n",
       "1  2007-01-01  2007-01-01 07:03:34+00:00  2007-01-01 07:03:34+00:00   \n",
       "2  2007-01-01  2007-01-01 11:29:56+00:00  2007-01-01 11:29:56+00:00   \n",
       "3  2007-01-01  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "4  2007-01-01  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "\n",
       "           sourceId                                           headline  \\\n",
       "0  e58c6279551b85cf  China's Daqing pumps 43.41 mln tonnes of oil i...   \n",
       "1  5a31c4327427f63f          FEATURE-In kidnapping, finesse works best   \n",
       "2  1cefd27a40fabdfe         PRESS DIGEST - Wall Street Journal - Jan 1   \n",
       "3  23768af19dc69992              PRESS DIGEST - New York Times - Jan 1   \n",
       "4  23768af19dc69992              PRESS DIGEST - New York Times - Jan 1   \n",
       "\n",
       "   urgency  takeSequence provider  \\\n",
       "0        3             1     RTRS   \n",
       "1        3             1     RTRS   \n",
       "2        3             1     RTRS   \n",
       "3        3             1     RTRS   \n",
       "4        3             1     RTRS   \n",
       "\n",
       "                                            subjects  \\\n",
       "0  {'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...   \n",
       "1  {'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...   \n",
       "2  {'IQ', 'RO', 'US', 'ID', 'RET', 'RTRS', 'ENR',...   \n",
       "3  {'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...   \n",
       "4  {'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...   \n",
       "\n",
       "                                           audiences       ...        \\\n",
       "0                                  {'O', 'Z', 'OIL'}       ...         \n",
       "1  {'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...       ...         \n",
       "2  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "3  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "4  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "\n",
       "   noveltyCount12H  noveltyCount24H noveltyCount3D noveltyCount5D  \\\n",
       "0                0                0              0              0   \n",
       "1                1                1              1              1   \n",
       "2                0                0              0              0   \n",
       "3                0                0              0              0   \n",
       "4                0                0              0              0   \n",
       "\n",
       "   noveltyCount7D  volumeCounts12H volumeCounts24H volumeCounts3D  \\\n",
       "0               0                0               0              3   \n",
       "1               1                1               1              3   \n",
       "2               0                0               0              5   \n",
       "3               0                0               0              5   \n",
       "4               0                0               0              0   \n",
       "\n",
       "   volumeCounts5D  volumeCounts7D  \n",
       "0               6               7  \n",
       "1               3               3  \n",
       "2              11              17  \n",
       "3              13              15  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train_df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "      <th>universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2606900.0</td>\n",
       "      <td>32.17</td>\n",
       "      <td>32.19</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034672</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2051600.0</td>\n",
       "      <td>11.08</td>\n",
       "      <td>11.12</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>-0.078708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1164800.0</td>\n",
       "      <td>37.99</td>\n",
       "      <td>37.51</td>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>23747329.0</td>\n",
       "      <td>86.23</td>\n",
       "      <td>84.74</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007425</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1208600.0</td>\n",
       "      <td>18.01</td>\n",
       "      <td>18.02</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  assetCode  assetName      volume   open  close  \\\n",
       "0  2007-02-01          0         28   2606900.0  32.17  32.19   \n",
       "1  2007-02-01          1         31   2051600.0  11.08  11.12   \n",
       "2  2007-02-01          2         18   1164800.0  37.99  37.51   \n",
       "3  2007-02-01          3         74  23747329.0  86.23  84.74   \n",
       "4  2007-02-01          4          3   1208600.0  18.01  18.02   \n",
       "\n",
       "   returnsClosePrevRaw1  returnsOpenPrevRaw1  returnsClosePrevRaw10  \\\n",
       "0              0.005938             0.005312              -0.001860   \n",
       "1              0.004517            -0.007168              -0.078708   \n",
       "2             -0.011594             0.025648               0.014332   \n",
       "3             -0.011548             0.016324              -0.048613   \n",
       "4              0.011791             0.025043               0.012929   \n",
       "\n",
       "   returnsClosePrevMktres10  returnsOpenPrevMktres10  returnsOpenNextMktres10  \\\n",
       "0                       NaN                      NaN                 0.034672   \n",
       "1                       NaN                      NaN                 0.027803   \n",
       "2                       NaN                      NaN                 0.024433   \n",
       "3                       NaN                      NaN                -0.007425   \n",
       "4                       NaN                      NaN                -0.017994   \n",
       "\n",
       "   universe  \n",
       "0       1.0  \n",
       "1       0.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Market (Done)\n",
    "\n",
    "#LabelEncode AssetName \n",
    "labelencoder_market_assetname = LabelEncoder()\n",
    "market_train_df_cleaned.iloc[:, 2] = labelencoder_market_assetname.fit_transform(market_train_df_cleaned.iloc[:, 2])\n",
    "\n",
    "#LabelEncode AssetCode \n",
    "labelencoder_market_assetcode = LabelEncoder()\n",
    "market_train_df_cleaned.iloc[:, 1] = labelencoder_market_assetcode.fit_transform(market_train_df_cleaned.iloc[:, 1])\n",
    "\n",
    "\n",
    "#Eliminate Unused Attributes \n",
    "market_train_df_usedCols = market_train_df_cleaned [['time','assetCode','assetName','volume','open','close',\n",
    "                          'returnsClosePrevRaw1','returnsOpenPrevRaw1',\n",
    "                          'returnsClosePrevRaw10','returnsClosePrevMktres10',\n",
    "                          'returnsOpenPrevMktres10','returnsOpenNextMktres10','universe']]\n",
    "\n",
    "\n",
    "#change time format\n",
    "market_train_df_usedCols['time'] =pd.to_datetime(market_train_df_usedCols.time)\n",
    "market_train_df_usedCols['time'] = market_train_df_usedCols['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "market_train_df_usedCols.head(5)\n",
    "\n",
    "#to decode the target label\n",
    "#ex: list(labelencoder_news_assetname.inverse_transform([6330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(market_train_df_usedCols.iloc[:,1:9]\n",
    "                                                    , market_train_df_usedCols.iloc[:,11], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.88756771e-11, 2.68013671e-11, 2.35394495e-11,\n",
       "       4.11406523e-15, 1.16211253e-16, 1.59337557e-17, 3.05099821e-18])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/mgd-pc/.local/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sourceTimestamp</th>\n",
       "      <th>firstCreated</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>e58c6279551b85cf</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'O', 'Z', 'OIL'}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>5a31c4327427f63f</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>{'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>1cefd27a40fabdfe</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time            sourceTimestamp               firstCreated  \\\n",
       "0  2007-01-01  2007-01-01 04:29:32+00:00  2007-01-01 04:29:32+00:00   \n",
       "1  2007-01-01  2007-01-01 07:03:34+00:00  2007-01-01 07:03:34+00:00   \n",
       "2  2007-01-01  2007-01-01 11:29:56+00:00  2007-01-01 11:29:56+00:00   \n",
       "3  2007-01-01  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "4  2007-01-01  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "\n",
       "           sourceId  headline  urgency  takeSequence  provider  subjects  \\\n",
       "0  e58c6279551b85cf         5        1             1         3        10   \n",
       "1  5a31c4327427f63f         8        1             1         3         6   \n",
       "2  1cefd27a40fabdfe        22        1             1         3        23   \n",
       "3  23768af19dc69992        21        1             1         3        36   \n",
       "4  23768af19dc69992        21        1             1         3        36   \n",
       "\n",
       "                                           audiences       ...        \\\n",
       "0                                  {'O', 'Z', 'OIL'}       ...         \n",
       "1  {'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...       ...         \n",
       "2  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "3  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "4  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "\n",
       "   noveltyCount12H  noveltyCount24H noveltyCount3D noveltyCount5D  \\\n",
       "0                0                0              0              0   \n",
       "1                1                1              1              1   \n",
       "2                0                0              0              0   \n",
       "3                0                0              0              0   \n",
       "4                0                0              0              0   \n",
       "\n",
       "   noveltyCount7D  volumeCounts12H volumeCounts24H volumeCounts3D  \\\n",
       "0               0                0               0              3   \n",
       "1               1                1               1              3   \n",
       "2               0                0               0              5   \n",
       "3               0                0               0              5   \n",
       "4               0                0               0              0   \n",
       "\n",
       "   volumeCounts5D  volumeCounts7D  \n",
       "0               6               7  \n",
       "1               3               3  \n",
       "2              11              17  \n",
       "3              13              15  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#News (Done)\n",
    "\n",
    "#LabelEncode AssetName \n",
    "labelencoder_news_assetname = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 8] = labelencoder_news_assetname.fit_transform(news_train_df_cleaned.iloc[:, 8])\n",
    "\n",
    "#LabelEncode AssetCode \n",
    "labelencoder_news_assetcode = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 7] = labelencoder_news_assetcode.fit_transform(news_train_df_cleaned.iloc[:, 7])\n",
    "\n",
    "#LabelEncode Subjects \n",
    "labelencoder_news_subjects = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 4] = labelencoder_news_subjects.fit_transform(news_train_df_cleaned.iloc[:, 4])\n",
    "\n",
    "#LabelEncode Audiences \n",
    "labelencoder_news_audiences = LabelEncoder()\n",
    "news_train_df_cleaned.iloc[:, 5] = labelencoder_news_audiences.fit_transform(news_train_df_cleaned.iloc[:, 5])\n",
    "\n",
    "#Eliminate Unused Attributes \n",
    "news_train_df_usedCols = news_train_df_cleaned[['time','urgency','subjects'\n",
    "                      ,'audiences','assetCodes','assetName'\n",
    "                      ,'relevance','sentimentClass','sentimentNegative',\n",
    "                      'sentimentNeutral','sentimentPositive','volumeCounts7D']]\n",
    "\n",
    "#change time format\n",
    "news_train_df_usedCols['time'] =pd.to_datetime(news_train_df_usedCols.time)\n",
    "news_train_df_usedCols['time'] = news_train_df_usedCols['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "news_train_df_cleaned.head(5)\n",
    "\n",
    "#Get Number of Unique items in attribute\n",
    "#ex: news_train_df_usedCols['subjects'].unique()\n",
    "\n",
    "#to decode the target label\n",
    "#ex: list(labelencoder_news_assetname.inverse_transform([6330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SameDay</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>n3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SameDay news\n",
       "0       1   n0\n",
       "1       1   n1\n",
       "2       1   n2\n",
       "3       1   n3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#table 1\n",
    "raw_data = {\n",
    "        'SameDay': ['1', '1', '1', '1'],\n",
    "        'news': [\"n0\", \"n1\", \"n2\", \"n3\"]}\n",
    "df_n = pd.DataFrame(raw_data, columns = [ 'SameDay','news'])\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SameDay</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>st0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>st1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>st2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>st3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SameDay stock\n",
       "0       1   st0\n",
       "1       1   st1\n",
       "2       1   st2\n",
       "3       1   st3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {\n",
    "        'SameDay': ['1', '1', '1', '1'],\n",
    "        'stock': [\"st0\", \"st1\", \"st2\", \"st3\"]}\n",
    "df_m = pd.DataFrame(raw_data, columns = [ 'SameDay','stock'])\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.merge(df_n, df_m,left_on='SameDay', right_on='SameDay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SameDay</th>\n",
       "      <th>news</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>n0</td>\n",
       "      <td>st0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n0</td>\n",
       "      <td>st1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>n0</td>\n",
       "      <td>st2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>n0</td>\n",
       "      <td>st3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>n1</td>\n",
       "      <td>st0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>n1</td>\n",
       "      <td>st1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>n1</td>\n",
       "      <td>st2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>n1</td>\n",
       "      <td>st3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>n2</td>\n",
       "      <td>st0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>n2</td>\n",
       "      <td>st1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>n2</td>\n",
       "      <td>st2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>n2</td>\n",
       "      <td>st3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>n3</td>\n",
       "      <td>st0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>n3</td>\n",
       "      <td>st1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>n3</td>\n",
       "      <td>st2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>n3</td>\n",
       "      <td>st3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SameDay news stock\n",
       "0        1   n0   st0\n",
       "1        1   n0   st1\n",
       "2        1   n0   st2\n",
       "3        1   n0   st3\n",
       "4        1   n1   st0\n",
       "5        1   n1   st1\n",
       "6        1   n1   st2\n",
       "7        1   n1   st3\n",
       "8        1   n2   st0\n",
       "9        1   n2   st1\n",
       "10       1   n2   st2\n",
       "11       1   n2   st3\n",
       "12       1   n3   st0\n",
       "13       1   n3   st1\n",
       "14       1   n3   st2\n",
       "15       1   n3   st3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgd-pc/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['st2', 'st2', 'st1']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "newdf.iloc[:, 2] = labelencoder_X_1.fit_transform(newdf.iloc[:, 2])\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('./datasets/Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2,\n",
       "       2, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 1, 2, 0, 0, 0,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 0], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:60, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "X[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 6.1900000e+02, 0.0000000e+00,\n",
       "       4.2000000e+01, 2.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0134888e+05])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
